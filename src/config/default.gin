# Default parameters

# Import necessary modules
from src.generators import base
from src.graph_providers import unified_provider
from src.graph_providers import base as graph_base
from src.mutation import text_based_evolution

# Retry configuration
CodeRetryHandler.max_attempts = 2
GraphProviderBase.retry_max_attempts = 2
GraphProviderBase.retry_prompt = None

# Text evolution configuration (Strategy used by TextBasedEvolution class)
TextBasedEvolution.evolution_strategy = 'collection_poison_avoidance_zero_shot'
GraphProviderBase.evolution_strategy = 'collection_poison_avoidance_zero_shot'

# Prompt configuration - Check storeprompts.py dict (Used by provider for code generation)
create_graph_provider.prompt_type = ''
create_graph_provider.prompt_name = ''

# Model-specific configurations
GraphUnifiedProvider.temperature = 0.65
GraphUnifiedProvider.max_tokens = 1024

# Model-specific name configurations
GraphUnifiedProvider.groq_model_name = "llama-3.3-70b-versatile" #"llama-3.1-8b-instant" # qwen-2.5-coder-32b llama-3.3-70b-versatile deepseek-r1-distill-qwen-32b
GraphUnifiedProvider.claude_model_name = "claude-3-5-haiku-latest" #"claude-3-5-sonnet-20241022" #claude-3-5-haiku-latest #claude-3-haiku-20240307
GraphUnifiedProvider.openai_model_name = "gpt-4o"
GraphUnifiedProvider.deepseek_model_name = "deepseek-chat"
