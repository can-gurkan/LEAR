# Default parameters

# Shared prompt config
prompt_type = 'groq'            # claude, simple, complex   
prompt_name = 'prompt3'         # prompt1        
evolution_strategy = 'simple'   # complex

# Import necessary modules
from src.generators import base
from src.graph_providers import unified_provider
from src.graph_providers import base as graph_base

# Retry configuration
CodeRetryHandler.max_attempts = 5
GraphProviderBase.retry_max_attempts = 5
GraphProviderBase.retry_prompt = 'generate_code_with_error'


# Set Prompt configuration
GraphProviderBase.evolution_strategy = %evolution_strategy
GraphProviderBase.prompt_type =  %prompt_type
GraphProviderBase.prompt_name =  %prompt_name
get_active_prompt_info.prompt_type = %prompt_type
get_active_prompt_info.prompt_name = %prompt_name


# Model-specific configurations
GraphUnifiedProvider.temperature = 0.65
GraphUnifiedProvider.max_tokens = 1024

# Model-specific name configurations
GraphUnifiedProvider.groq_model_name = "llama-3.3-70b-versatile" # qwen-2.5-coder-32b llama-3.3-70b-versatile deepseek-r1-distill-qwen-32b
GraphUnifiedProvider.claude_model_name = "claude-3-5-sonnet-20241022"
GraphUnifiedProvider.openai_model_name = "gpt-4o"
GraphUnifiedProvider.deepseek_model_name = "deepseek-chat"



